{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.Tensor([[0, 1, 0, 0], [0, 1, 0, 0], [0, 1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 312, 312])\n",
      "torch.Size([2, 220, 220])\n"
     ]
    }
   ],
   "source": [
    "# now run a prediction on a slice \n",
    "from unet.dataset import SegThorImagesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_csv = \"data/train_patient_idx_sorted.csv\"\n",
    "data_dir = 'data/train'\n",
    "\n",
    "train_dataset = SegThorImagesDataset(\n",
    "    patient_idx_file=train_csv,\n",
    "    root_dir=data_dir,\n",
    "    img_crop_size=312, \n",
    "    mask_output_size=220,\n",
    "    cache_size=1\n",
    "    )\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_iter = iter(train_dl)\n",
    "for i in range(550):\n",
    "    X, Y = next(dl_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 312, 312])\n",
      "torch.Size([2, 220, 220])\n",
      "preds shape: torch.Size([2, 5, 220, 220])\n",
      "torch.Size([2, 4, 220, 220])\n",
      "Target class weights: tensor([[ 167,    1,  405, 1199],\n",
      "        [ 160,    1,  254, 1212]])\n",
      "Class Weights: tensor([[3.5856e-05, 1.0000e+00, 6.0966e-06, 6.9560e-07],\n",
      "        [3.9062e-05, 1.0000e+00, 1.5500e-05, 6.8076e-07]])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "preds = torch.rand([2, 5, 220, 220])\n",
    "print(f'preds shape: {preds.shape}')\n",
    "\n",
    "# List of classes\n",
    "classes = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# need to transform Y into a multi-channel tensor to align with preds\n",
    "multi_channel_Y = torch.stack([(Y == c).int() for c in classes], dim=1)\n",
    "\n",
    "# add one value to multi_channel_Y\n",
    "multi_channel_Y[:, 1, 1, 1] = 1\n",
    "\n",
    "print(multi_channel_Y.shape)\n",
    "\n",
    "# Sum the boolean masks to get the count of each class\n",
    "target_class_weights = torch.sum(multi_channel_Y, dim=(-1, -2))\n",
    "print(f\"Target class weights: {target_class_weights}\")\n",
    "\n",
    "class_weights = 1 / (target_class_weights * target_class_weights).clamp(1e-6)\n",
    "print(f\"Class Weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection: tensor([[8.2069e+01, 4.6458e-01, 2.0316e+02, 6.2095e+02],\n",
      "        [7.8675e+01, 8.1349e-02, 1.2879e+02, 6.0542e+02]])\n",
      "Union: tensor([[24260.6055, 24248.4062, 24694.6797, 25433.5703],\n",
      "        [24292.5195, 24104.7344, 24458.5605, 25467.1445]])\n"
     ]
    }
   ],
   "source": [
    "# ignore the 0 class \n",
    "\n",
    "# intersection mask \n",
    "intersection = (preds[:, 1:, :, :] * multi_channel_Y).sum(dim=(-1, -2))\n",
    "print(f\"Intersection: {intersection}\")\n",
    "\n",
    "# union \n",
    "union = (preds[:, 1:, :, :] + multi_channel_Y).sum(dim=(-1, -2))\n",
    "\n",
    "print(f\"Union: {union}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0180, 0.0161])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average over labels \n",
    "2*( (intersection*class_weights) / (union*class_weights) ).mean(dim=1)\n",
    "# average over batch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GDL weighting: the contribution of each label is corrected by the inverse of its volume\n",
    "class_weight = preds.sum(-1)\n",
    "w_l = 1 / (w_l * w_l).clamp(min=self.epsilon)\n",
    "w_l.requires_grad = False\n",
    "\n",
    "intersect = (input * target).sum(-1)\n",
    "intersect = intersect * w_l\n",
    "\n",
    "denominator = (input + target).sum(-1)\n",
    "denominator = (denominator * w_l).clamp(min=self.epsilon)\n",
    "\n",
    "return 2 * (intersect.sum() / denominator.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_l = input.sum()\n",
    "\n",
    "w_l = 1 / (w_l * w_l).clamp(min=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1111)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GeneralizedDiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/pdf/1707.03237.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classes = torch.tensor([1, 2, 3, 4]), epsilon=1e-6, ):\n",
    "        super(GeneralizedDiceLoss, self).__init__()\n",
    "        self.classes = classes \n",
    "        # normalize the logits, since each channel is predicting its own class\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1) # channel\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def normalization(self, input):\n",
    "        ## sigmoid to squash inputs\n",
    "        ## softmax across channels to get to probabilities\n",
    "        logits = self.sigmoid(input)\n",
    "        proba = self.softmax(logits)\n",
    "        return proba\n",
    "\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # get probabilities from logits\n",
    "        input = self.normalization(input)\n",
    "\n",
    "        # compute per batch item multi-label dice\n",
    "        per_item_dice = self.dice(input, target)\n",
    "        batch_losses = 1. - per_item_dice\n",
    "        # sum across batches\n",
    "        return batch_losses.sum()\n",
    "\n",
    "    def dice(self, input, target):\n",
    "        \"\"\"\n",
    "        input shape expects batch x class x h x w (drop the 0 class)\n",
    "        target shape expects batch x h x w\n",
    "        \"\"\"\n",
    "        # List of classes\n",
    "        classes = torch.tensor([1, 2, 3, 4])\n",
    "        # need to transform target into a multi-channel tensor to align with preds\n",
    "        multi_channel_target = torch.stack([(target == c).int() for c in self.classes], dim=1)\n",
    "        # Sum the boolean masks to get the count of each class\n",
    "        target_class_weights = torch.sum(multi_channel_target, dim=(-1, -2))\n",
    "        class_weights = 1 / (target_class_weights * target_class_weights).clamp(1e-6)\n",
    "        class_weights.requires_grad = False\n",
    "\n",
    "        intersection = (input * multi_channel_target).sum(dim=(-1, -2))\n",
    "        union = (input + multi_channel_target).sum(dim=(-1, -2))\n",
    "        # take average over labels \n",
    "        batch_dice = 2*( (intersection*class_weights) / (union*class_weights) ).mean(dim=1)\n",
    "        return batch_dice\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = GeneralizedDiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 220, 220])\n",
      "torch.Size([2, 5, 220, 220])\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "\n",
    "preds = torch.rand([2, 5, 220, 220])\n",
    "\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9659)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(preds[:, 1:, :, :], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecs_fp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
